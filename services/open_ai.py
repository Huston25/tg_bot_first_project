import logging

from openai import AsyncOpenAI
from config import CHAT_GPT_TOKEN

logger = logging.getLogger(__name__)
client = AsyncOpenAI(api_key=CHAT_GPT_TOKEN)


async def get_random_fact():
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ª—É—á–∞–π–Ω—ã–π —Ñ–∞–∫—Ç –æ—Ç ChatGPT"""
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞–µ—Ç –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–µ –∏ –ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ–∞–∫—Ç—ã. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ. –ú–æ–∂–µ—à—å –¥–æ–±–∞–≤–∏—Ç—å —à—É—Ç–æ–∫"
                },
                {
                    "role": "user",
                    "content": "–†–∞—Å—Å–∫–∞–∂–∏ –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π —Å–ª—É—á–∞–π–Ω—ã–π —Ñ–∞–∫—Ç –∏–∑ –ª—é–±–æ–π –æ–±–ª–∞—Å—Ç–∏ –∑–Ω–∞–Ω–∏–π. –§–∞–∫—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø–æ–∑–Ω–∞–≤–∞—Ç–µ–ª—å–Ω—ã–º, —É–¥–∏–≤–∏—Ç–µ–ª—å–Ω—ã–º –∏ –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º (–º–∞–∫—Å–∏–º—É–º 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."
                }
            ],
            max_tokens=200,
            temperature=0.8
        )

        fact = response.choices[0].message.content.strip()
        logger.info("–§–∞–∫—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI")
        return fact

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ñ–∞–∫—Ç–∞ –æ—Ç OpenAI: {e}")
        return "ü§î –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ñ–∞–∫—Ç –≤ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ!"


async def get_chatgpt_response(user_message: str):
    """–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç ChatGPT –Ω–∞ –ø—Ä–æ–∏–∑–≤–æ–ª—å–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ, –±—É–¥—å –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–º –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–º. –ï—Å–ª–∏ –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç, —á–µ—Å—Ç–Ω–æ –æ–± —ç—Ç–æ–º —Å–∫–∞–∂–∏."
                },
                {
                    "role": "user",
                    "content": user_message
                }
            ],
            max_tokens=1000,
            temperature=0.7
        )

        answer = response.choices[0].message.content.strip()
        logger.info("–û—Ç–≤–µ—Ç —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI")
        return answer

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI: {e}")
        return "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ ChatGPT. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ!"


async def get_personality_response(user_message, personality_prompt):
    try:
        response = await client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": personality_prompt
                },
                {
                    "role": "user",
                    "content": user_message
                }
            ],
            max_tokens=1000,
            temperature=1
        )

        answer = response.choices[0].message.content.strip()
        logger.info("–û—Ç–≤–µ—Ç –æ—Ç –ª–∏—á–Ω–æ—Å—Ç–∏ —É—Å–ø–µ—à–Ω–æ –ø–æ–ª—É—á–µ–Ω –æ—Ç OpenAI")
        return answer

    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ –æ—Ç–≤–µ—Ç–∞ –æ—Ç –ª–∏—á–Ω–æ—Å—Ç–∏: {e}")
        return "üòî –ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ª–∏—á–Ω–æ—Å—Ç–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ!"


async def get_recommendation_response(
        type_chosen: str,
        origin: str,
        genre: str,
        mood: str,
        goal: str
, used=None) -> str:
    used = used or []
    used_text = "\n".join(f" - {item}" for item in used) if used else "–ù–µ—Ç"
    origin_map = {
        "russian": "–†—É—Å—Å–∫–æ–µ",
        "foreign": "–ó–∞—Ä—É–±–µ–∂–Ω–æ–µ",
        "any": "–ù–µ –≤–∞–∂–Ω–æ"
    }
    origin_text = origin_map.get(origin)
    prompt = (f"""–¢—ã –≤—ã—Å—Ç—É–ø–∞–µ—à—å –∫–∞–∫ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ –ø–æ–º–æ—á—å –≤—ã–±—Ä–∞—Ç—å {type_chosen} 
        ({origin_text})
            –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ –ù–µ –ø—Ä–µ–¥–ª–∞–≥–∞–π –ø–æ–≤—Ç–æ—Ä–Ω–æ {used_text}.
            –£—á–∏—Ç—ã–≤–∞–π:
                - –ñ–∞–Ω—Ä: {genre}
                - –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {mood}
                - –¶–µ–ª—å: {goal}
            –§–æ—Ä–º–∞—Ç:
            –ù–∞–∑–≤–∞–Ω–∏–µ:
            –ê–≤—Ç–æ—Ä/–†–µ–∂–∏—Å—Å–µ—Ä:
            –û–ø–∏—Å–∞–Ω–∏–µ:
            –ü–æ—á–µ–º—É —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–æ:\n\n
            –°–ø–∏—Å–æ–∫ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π: \n{used_text}""")

    try:
        response = await client.chat.completions.create(
            model='gpt-3.5-turbo',
            messages=[
                {
                    'role': 'system',
                    'content': '–¢—ã —É–º–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫, –∫–æ—Ç–æ—Ä—ã–π —Å–æ–≤–µ—Ç—É–µ—Ç –∫–Ω–∏–≥–∏, —Ñ–∏–ª—å–º—ã –∏ —Å–µ—Ä–∏–∞–ª—ã'
                },
                {
                    'role': 'user',
                    'content': prompt
                }
            ],
            temperature=0.9
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f'–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ —Ñ–∏–ª—å–º–∞–º –∏ –∫–Ω–∏–≥–∞–º: {e}')
        return '–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –≤ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è—Ö. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–≤—Ç–æ—Ä–∏—Ç—å'
